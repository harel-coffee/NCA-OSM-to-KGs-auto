{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense\n",
    "import pickle\n",
    "import psycopg2\n",
    "import scipy\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "from keras import activations\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Italy\"\n",
    "KG = \"Wikidata\" #options: Wikidata/Wikipedia\n",
    "data = pd.read_csv('/home/dsouza/WorldKGFinalCode/Data/'+KG+'/'+country+'/'+country+'.csv', sep='\\t', encoding='utf-8',)\n",
    "latentSpace = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data._get_numeric_data()\n",
    "num[num > 1] = 1\n",
    "labelName = []\n",
    "colNameOsm = []\n",
    "colNameWiki = []\n",
    "for col in data.columns:\n",
    "    if 'cls_' in col:\n",
    "        labelName.append(col)\n",
    "    if 'osmTagKey_' in col:\n",
    "        try:\n",
    "            if data[col].value_counts()[1]>50:\n",
    "                colNameOsm.append(col)\n",
    "        except KeyError:\n",
    "            KeyError\n",
    "    elif 'prop_' in col and 'prop_instance of' not in col:\n",
    "        colNameWiki.append(col)\n",
    "labels =  data[labelName]\n",
    "columnsOSM = data[colNameOsm]\n",
    "columnsWiki = data[colNameWiki]\n",
    "labelNameDict = {}\n",
    "for i in range(len(labelName)):\n",
    "    labelNameDict[i] = labelName[i]\n",
    "columnsWikiDict = {}\n",
    "for i in range(len(colNameWiki)):\n",
    "    columnsWikiDict[i] = colNameWiki[i]\n",
    "colNameOsmDict = {}\n",
    "for i in range(len(colNameOsm)):\n",
    "    colNameOsmDict[i] = colNameOsm[i]\n",
    "        #print(c)\n",
    "columns = colNameOsm+colNameWiki\n",
    "columnsDict = {}\n",
    "for i in range(len(columns)):\n",
    "    columnsDict[i] = columns[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_var = 1\n",
    "kf = KFold(n_splits = 3, random_state = 42, shuffle = True)\n",
    "train_index, val_index = list(kf.split(columnsOSM,labels))[0]\n",
    "osm_train = columnsOSM.iloc[train_index].values\n",
    "osm_test = columnsOSM.iloc[val_index].values\n",
    "wiki_train = columnsWiki.iloc[train_index].values\n",
    "wiki_test = columnsWiki.iloc[val_index].values\n",
    "y_train = labels.iloc[train_index].values\n",
    "y_test = labels.iloc[val_index].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data for discriminator\n",
    "def generate_adverse_labels(osm, wiki):\n",
    "    osm_part = np.ones((osm.shape[0], 1))\n",
    "    wiki_part = np.zeros((wiki.shape[0], 1))\n",
    "    return np.concatenate((osm_part, wiki_part))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(x,y):\n",
    "    # Import a dataset with X and multi-label y\n",
    "\n",
    "    lp = LabelPowerset()\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "    # Applies the above stated multi-label (ML) to multi-class (MC) transformation.\n",
    "    yt = lp.transform(y)\n",
    "\n",
    "    X_resampled, y_resampled = ros.fit_sample(x, yt)\n",
    "    # Inverts the ML-MC transformation to recreate the ML set\n",
    "    y_resampled = lp.inverse_transform(y_resampled)\n",
    "    y_resampled = y_resampled.toarray()\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_input(osm_train, osm_test, wiki_train, wiki_test, y_train, y_test):\n",
    "    \n",
    "    #total length of the input = OSM tags + OSM keys + KG properties\n",
    "    maxlen =osm_train.shape[1]+wiki_train.shape[1]\n",
    "    osm_train_pad = pad_sequences(osm_train, padding='post', maxlen=maxlen)\n",
    "    osm_test_pad = pad_sequences(osm_test, padding='post', maxlen=maxlen)\n",
    "    wiki_train_pad = pad_sequences(wiki_train, padding='pre', maxlen=maxlen)\n",
    "    wiki_test_pad = pad_sequences(wiki_test, padding='pre', maxlen=maxlen)\n",
    "    \n",
    "    print(\"osm_train\", osm_train_pad.shape, \"wiki_train\", wiki_train_pad.shape)\n",
    "    x_train = np.concatenate((osm_train_pad, wiki_train_pad))\n",
    "    print(\"x_train\", x_train.shape)\n",
    "\n",
    "    print(\"osm_test\", osm_test_pad.shape, \"wiki_test\", wiki_test_pad.shape)\n",
    "    x_test = np.concatenate((osm_test_pad, wiki_test_pad))\n",
    "    print(\"x_test\", x_test.shape)\n",
    "\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    y_train = np.concatenate((y_train, y_train))\n",
    "    print(\"y_train\", y_train.shape)\n",
    "\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    y_test = np.concatenate((y_test, y_test))\n",
    "    print(\"y_test\", y_test.shape)\n",
    "\n",
    "    adverse_train = generate_adverse_labels(osm_train, wiki_train)\n",
    "    print(\"adverse_train\", adverse_train.shape)\n",
    "    adverse_test = generate_adverse_labels(osm_test, wiki_test)\n",
    "    print(\"adverse_test\", adverse_test.shape)\n",
    "\n",
    "    \n",
    "    return x_train, y_train, adverse_train, x_test, y_test, adverse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osm_train (12467, 173) wiki_train (12467, 173)\n",
      "x_train (24934, 173)\n",
      "osm_test (6234, 173) wiki_test (6234, 173)\n",
      "x_test (12468, 173)\n",
      "y_train (12467, 20)\n",
      "y_train (24934, 20)\n",
      "y_test (6234, 20)\n",
      "y_test (12468, 20)\n",
      "adverse_train (24934, 1)\n",
      "adverse_test (12468, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, adverse_train, x_test, y_test, adverse_test = transform_input(osm_train, osm_test, wiki_train, wiki_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss for adversarial component\n",
    "def maxLoss(y_true, y_pred):\n",
    "    return -1.0 * binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaModel:\n",
    "\n",
    "    def __init__(self, no_inputs, no_outputs):\n",
    "        optimizer = Adam(0.0001, 0.5)\n",
    "        self.model = self.define_discriminator(no_inputs, no_outputs)\n",
    "        \n",
    "        losses = {\n",
    "                \"class\": 'binary_crossentropy',\n",
    "                \"adverse\": maxLoss,\n",
    "                }\n",
    "        self.model.compile(loss=losses,\n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "    def define_discriminator(self, no_inputs, no_outputs):\n",
    "        inputs = Input(shape=(no_inputs,), name = 'input')\n",
    "        \n",
    "        X_1 = Dense(100, activation='relu', name = 'layer1')(inputs)\n",
    "        latent_rep = Dense(latentSpace, activation='relu', name = 'latentRep')(X_1)\n",
    "\n",
    "        # KG classfication\n",
    "        fc_1 = Dense(latentSpace, activation='relu', name = 'layer3')(latent_rep)\n",
    "        fc_2 = Dense(latentSpace , activation='relu', name = 'layer4')(fc_1)\n",
    "        \n",
    "        classifier = Dense(no_outputs, activation='sigmoid', name = 'class')(fc_2)\n",
    "        \n",
    "        #adversarial compenent\n",
    "        adverse= Dense(1, activation='softmax', name = 'adverse')(latent_rep)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs, [classifier, adverse])\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Setting the seed for numpy-generated random numbers\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setting the seed for python random numbers\n",
    "rn.seed(1254)\n",
    "\n",
    "# Setting the graph-level random seed.\n",
    "tf.set_random_seed(89)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "      intra_op_parallelism_threads=1,\n",
    "      inter_op_parallelism_threads=1)\n",
    "\n",
    "#Force Tensorflow to use a single thread\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SchemaModel(x_train.shape[1], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 173)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 100)          17400       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "latentRep (Dense)               (None, 30)           3030        layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 30)           930         latentRep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer4 (Dense)                  (None, 30)           930         layer3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 20)           620         layer4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "adverse (Dense)                 (None, 1)            31          latentRep[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,941\n",
      "Trainable params: 22,941\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = m.model.fit(x=x_train, y=[y_train, adverse_train], epochs=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassIndex(clsId, y_test):\n",
    "    t = np.argwhere(y_test>0)\n",
    "    clsIndex = []\n",
    "    for i in range(len(t)):\n",
    "        if t[i][1] == clsId:\n",
    "            clsIndex.append(t[i][0])\n",
    "    return clsIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassAcc(y_test, y_pred, cls, threshold):\n",
    "    indexes = getClassIndex(cls, y_test)\n",
    "    total_number = len(indexes)\n",
    "    fn = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if i in indexes:\n",
    "            if y_pred[i][cls]>threshold:\n",
    "                tp = tp+1\n",
    "            elif y_pred[i][cls]<threshold:\n",
    "                fn = fn+1\n",
    "        elif i not in indexes:\n",
    "            if y_pred[i][cls]>threshold:\n",
    "                fp = fp+1\n",
    "    try:\n",
    "        precision = tp/(tp+fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "    try:\n",
    "        recall = tp/(tp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "    return cls, total_number, precision, recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m.model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get per class accuracy\n",
    "for i in range(y_test.shape[1]):\n",
    "    print(getClassAcc(y_test, a[0],i , 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the array for testing with one row for 1 input\n",
    "testKeyTag = np.zeros((x_train.shape[1], x_train.shape[1]))\n",
    "for i in range(len(testKeyTag)):\n",
    "    testKeyTag[i][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the activations of the last layer\n",
    "get_layer_output = K.function([m.model.layers[0].input],\n",
    "                                  [m.model.layers[5].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output = get_layer_output(testKeyTag)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSMTag</th>\n",
       "      <th>WikidataClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amenity=place_of_worship</td>\n",
       "      <td>church building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amenity=theatre</td>\n",
       "      <td>theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amenity=townhall</td>\n",
       "      <td>comune of Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cemetery=grave</td>\n",
       "      <td>tomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>historic=archaeological_site</td>\n",
       "      <td>archaeological site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>place=village</td>\n",
       "      <td>village in India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>public_transport=stop_position</td>\n",
       "      <td>elevated station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>railway=station</td>\n",
       "      <td>elevated station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>railway=station</td>\n",
       "      <td>metro station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>railway=station</td>\n",
       "      <td>station located on surface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             OSMTag               WikidataClass\n",
       "0          amenity=place_of_worship             church building\n",
       "1                   amenity=theatre                     theatre\n",
       "2                  amenity=townhall             comune of Italy\n",
       "3                    cemetery=grave                        tomb\n",
       "4      historic=archaeological_site         archaeological site\n",
       "..                              ...                         ...\n",
       "104                   place=village            village in India\n",
       "105  public_transport=stop_position            elevated station\n",
       "106                 railway=station            elevated station\n",
       "107                 railway=station               metro station\n",
       "108                 railway=station  station located on surface\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatches():\n",
    "    listPrecRecall = []\n",
    "    for i in range(len(testKeyTag)):\n",
    "        if '=' in columnsDict[np.argmax(testKeyTag[i])] and not any(map(str.isdigit, columnsDict[np.argmax(testKeyTag[i])]))  and '=yes' not in columnsDict[np.argmax(testKeyTag[i])] and '=no' not in columnsDict[np.argmax(testKeyTag[i])]:\n",
    "            for j in range(len(layer_output[i])):\n",
    "                listPrecRecall.append((columnsDict[np.argmax(testKeyTag[i])].replace('osmTagKey_',''),labelNameDict[j].replace('cls_',''), layer_output[i][j]))\n",
    "    return listPrecRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = getMatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
